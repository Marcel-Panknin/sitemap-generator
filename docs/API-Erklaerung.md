# Sitemap Generator - API Funktionen Erkl√§rt

## √úbersicht
Der Sitemap Generator bietet eine einfache API zum Erstellen von XML-Sitemaps durch das Crawlen von Websites. Hier sind alle wichtigen Funktionen verst√§ndlich erkl√§rt.

---

## üöÄ Hauptmethoden

### `start()`
**Was macht es:** Startet den Crawler und beginnt mit der Sitemap-Erstellung.

```javascript
const generator = SitemapGenerator('https://example.com');
generator.start(); // Crawler startet asynchron
```

**Wichtig:** 
- L√§uft asynchron (blockiert nicht den Code)
- Schreibt die Sitemap automatisch auf die Festplatte
- Nutzen Sie Event-Listener um zu wissen, wann es fertig ist

---

### `stop()`
**Was macht es:** Stoppt den laufenden Crawler sofort.

```javascript
generator.stop(); // Crawler wird gestoppt, Sitemap-Erstellung wird abgebrochen
```

**Wann verwenden:** 
- Wenn der Crawler zu lange braucht
- Bei Fehlern oder wenn Sie abbrechen m√∂chten

---

### `getCrawler()`
**Was macht es:** Gibt Ihnen direkten Zugriff auf den internen Crawler.

```javascript
const crawler = generator.getCrawler();

// Beispiel: Bestimmte URLs ignorieren
crawler.addFetchCondition((queueItem, referrerQueueItem, callback) => {
  // URLs mit "/admin/" werden ignoriert
  const shouldCrawl = !queueItem.path.includes('/admin/');
  callback(null, shouldCrawl);
});
```

**Praktische Anwendungen:**
- URLs mit bestimmten Mustern ausschlie√üen
- Crawler-Verhalten anpassen
- Erweiterte Konfiguration

---

### `getSitemap()`
**Was macht es:** Gibt Ihnen Zugriff auf die Sitemap-Instanz.

```javascript
const crawler = generator.getCrawler();
const sitemap = generator.getSitemap();

// Statische URLs manuell hinzuf√ºgen
crawler.on('crawlstart', () => {
  sitemap.addURL('/impressum');
  sitemap.addURL('/datenschutz');
  sitemap.addURL('/kontakt');
});
```

**Wann n√ºtzlich:**
- Statische Seiten hinzuf√ºgen, die der Crawler nicht findet
- URLs manuell zur Sitemap hinzuf√ºgen
- Sitemap-Inhalt direkt manipulieren

---

### `queueURL(url)`
**Was macht es:** F√ºgt eine URL zur Crawler-Warteschlange hinzu.

```javascript
// Diese URL wird auch gecrawlt, auch wenn sie nicht verlinkt ist
generator.queueURL('https://example.com/versteckte-seite');
```

**Praktisch f√ºr:**
- Seiten die nicht verlinkt sind
- Wichtige URLs die der Crawler √ºbersehen k√∂nnte
- Manuelle Steuerung des Crawling-Prozesses

---

## üì° Event-System

Der Generator sendet Events aus, auf die Sie reagieren k√∂nnen:

### `'add'` Event
```javascript
generator.on('add', (url) => {
  console.log('‚úÖ URL zur Sitemap hinzugef√ºgt:', url);
});
```

### `'done'` Event
```javascript
generator.on('done', () => {
  console.log('üéâ Sitemap-Erstellung abgeschlossen!');
  // Hier k√∂nnen Sie weitere Aktionen ausf√ºhren
});
```

### `'error'` Event
```javascript
generator.on('error', (error) => {
  console.log('‚ùå Fehler beim Crawlen:', error);
  // error enth√§lt: { code: 404, message: 'Not found.', url: 'http://...' }
});
```

### `'ignore'` Event
```javascript
generator.on('ignore', (url) => {
  console.log('‚ö†Ô∏è URL ignoriert (robots.txt oder noindex):', url);
});
```

---

## üõ†Ô∏è Praktisches Beispiel

```javascript
const SitemapGenerator = require('sitemap-generator');

// Generator erstellen
const generator = SitemapGenerator('https://meine-website.de', {
  filepath: './meine-sitemap.xml',
  stripQuerystring: true
});

// Crawler anpassen
const crawler = generator.getCrawler();
crawler.addFetchCondition((queueItem, referrerQueueItem, callback) => {
  // Admin-Bereich und tempor√§re Seiten ignorieren
  const shouldIgnore = queueItem.path.match(/\/(admin|temp|test)\//);
  callback(null, !shouldIgnore);
});

// Sitemap-Instanz f√ºr manuelle URLs
const sitemap = generator.getSitemap();

// Event-Listener einrichten
generator.on('add', (url) => console.log('‚ûï', url));
generator.on('error', (error) => console.log('‚ùå', error.message));
generator.on('done', () => {
  console.log('‚úÖ Sitemap fertig erstellt!');
  console.log('üìÅ Datei: ./meine-sitemap.xml');
});

// Wichtige URLs manuell hinzuf√ºgen
crawler.on('crawlstart', () => {
  sitemap.addURL('/sitemap'); // Meta-Seite
  sitemap.addURL('/rss.xml'); // RSS Feed
});

// Versteckte aber wichtige Seite zur Warteschlange hinzuf√ºgen
generator.queueURL('https://meine-website.de/versteckte-landingpage');

// Crawler starten
generator.start();
```

---

## üí° Tipps f√ºr die Praxis

1. **Event-Listener immer vor `start()` definieren**
2. **`getCrawler()` f√ºr erweiterte Filterung nutzen**
3. **`getSitemap()` f√ºr statische URLs verwenden**
4. **`queueURL()` f√ºr wichtige, nicht verlinkte Seiten**
5. **`stop()` als Notbremse bei Problemen**

---

## üîó Weiterf√ºhrende Informationen

- F√ºr detaillierte Crawler-Optionen: [SimpleCrawler Dokumentation](https://github.com/simplecrawler/simplecrawler#readme)
- F√ºr Konfigurationsoptionen: Siehe README.md Abschnitt "Options"